{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet-ish Architecture Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWb9DeIUaQiJ",
        "colab_type": "code",
        "outputId": "931e402e-c7b4-43ec-d2e6-30324f705da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sharable_links = ['https://drive.google.com/open?id=1octn7viLBP10qqVkYv5QLaU6RiwpNwFc']\n",
        "filenames = ['NewestV3BalancedDatasetWithLatentSpaceOutputs.zip']\n",
        "\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def link2id(link):\n",
        "  pos = link.find(\"=\")\n",
        "  return link[pos+1:]\n",
        "\n",
        "ids = [link2id(link) for link in sharable_links]\n",
        "\n",
        "for i in range(len(ids)):\n",
        "  downloaded = drive.CreateFile({'id': ids[i]})\n",
        "  downloaded.GetContentFile(filenames[i])\n",
        "  print(filenames[i],\" loaded.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NewestV3BalancedDatasetWithLatentSpaceOutputs.zip  loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIR1J3nAabac",
        "colab_type": "code",
        "outputId": "c50629b8-b037-4b38-c73e-fe15a6fea926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!unzip NewestV3BalancedDatasetWithLatentSpaceOutputs.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  NewestV3BalancedDatasetWithLatentSpaceOutputs.zip\n",
            "   creating: NewestV3BalancedDatasetWithLatentSpaceOutputs/\n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedLatentSpaceObj.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputSubImages.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedOutputPredictions.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedLatentSpaceSub.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputObjImages.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputObjVectors.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputSubVectors.npy  \n",
            "  inflating: NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputImages.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrumlBWIa3Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "bboxImage = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputImages.npy\")\n",
        "objLatentVector = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedLatentSpaceObj.npy\")\n",
        "subLatentVector = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedLatentSpaceSub.npy\")\n",
        "objWordVector = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputObjVectors.npy\")\n",
        "subWordVector = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedInputSubVectors.npy\")\n",
        "\n",
        "predOutput = np.load(\"NewestV3BalancedDatasetWithLatentSpaceOutputs/balancedOutputPredictions.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oql5shExblVh",
        "colab_type": "code",
        "outputId": "dd8f451b-5505-428d-d165-84ae4b2f8375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "print(bboxImage.shape)\n",
        "print(objLatentVector.shape)\n",
        "print(subLatentVector.shape)\n",
        "print(objWordVector.shape)\n",
        "print(subWordVector.shape)\n",
        "print(predOutput.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14216, 50, 50, 1)\n",
            "(14216, 9216)\n",
            "(14216, 9216)\n",
            "(14216, 50)\n",
            "(14216, 50)\n",
            "(14216, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOeoBcvUu8NP",
        "colab_type": "code",
        "outputId": "c93f323c-6461-420d-82ab-2f009bccd049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "indices = np.arange(0, bboxImage.shape[0])\n",
        "filtered_indices = np.zeros(shape=[0])\n",
        "\n",
        "predicates = [\"on\", \"next to\", \"behind\", \"under\"]\n",
        "for i in range(4):\n",
        "  indices_with_id = indices[predOutput[:,0]==i]\n",
        "  print(indices_with_id.shape)\n",
        "  np.random.shuffle(indices_with_id)\n",
        "  filtered_indices = np.concatenate([filtered_indices, indices_with_id])\n",
        "print(filtered_indices.shape)\n",
        "filtered_indices = np.array(filtered_indices, dtype=np.int32)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6501,)\n",
            "(3982,)\n",
            "(1753,)\n",
            "(1980,)\n",
            "(14216,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy4jltZSwv4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filteredBBoxImage = bboxImage[filtered_indices]\n",
        "filteredObjLatentVector = objLatentVector[filtered_indices]\n",
        "filteredSubLatentVector = subLatentVector[filtered_indices]\n",
        "filteredObjWordVector = objWordVector[filtered_indices]\n",
        "filteredSubWordVector = subWordVector[filtered_indices]\n",
        "filteredPredOutput = predOutput[filtered_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFWAbfIszHVT",
        "colab_type": "code",
        "outputId": "38e5dc51-3453-46b1-f3b9-51bb9ddc5286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "indices = np.arange(0, filteredBBoxImage.shape[0])\n",
        "chosen_indices = []\n",
        "total_classes = 0\n",
        "for i in range(4):\n",
        "  indices_id = indices[filteredPredOutput[:,0]==i]\n",
        "  # if indices_id.shape[0]>=threshold:\n",
        "  chosen_indices.append(i)\n",
        "  filteredPredOutput[indices_id] = total_classes\n",
        "  total_classes += 1\n",
        "print(chosen_indices)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzlRUldJ1QWa",
        "colab_type": "code",
        "outputId": "657c4aa6-8a10-4124-87c0-569d8f1d3632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicates = [\"on\", \"next to\", \"behind\", \"under\"]\n",
        "chosen_preds = []\n",
        "for i in range(len(chosen_indices)):\n",
        "  chosen_preds.append(predicates[chosen_indices[i]])\n",
        "\n",
        "print(chosen_preds)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['on', 'next to', 'behind', 'under']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9OHGK4ep2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(0, filteredBBoxImage.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "filteredBBoxImage = filteredBBoxImage[indices]\n",
        "filteredObjLatentVector = filteredObjLatentVector[indices]\n",
        "filteredSubLatentVector = filteredSubLatentVector[indices]\n",
        "filteredObjWordVector = filteredObjWordVector[indices]\n",
        "filteredSubWordVector = filteredSubWordVector[indices]\n",
        "filteredPredOutput = filteredPredOutput[indices]\n",
        "\n",
        "nonOverlappingIndices = indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THEdWovM8bpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_split = 0.1\n",
        "\n",
        "test_set_size = int(nonOverlappingIndices.shape[0]*test_split)\n",
        "\n",
        "def createTestTrainSplit(data, test_set_size=test_set_size):\n",
        "  return data[test_set_size:], data[:test_set_size]\n",
        "\n",
        "trainBBoxImage, testBBoxImage = createTestTrainSplit(filteredBBoxImage)\n",
        "trainObjLatentVector, testObjLatentVector = createTestTrainSplit(filteredObjLatentVector)\n",
        "trainSubLatentVector, testSubLatentVector = createTestTrainSplit(filteredSubLatentVector)\n",
        "trainObjWordVector, testObjWordVector = createTestTrainSplit(filteredObjWordVector)\n",
        "trainSubWordVector, testSubWordVector = createTestTrainSplit(filteredSubWordVector)\n",
        "trainPred, testPred = createTestTrainSplit(filteredPredOutput)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwrGMaJj8rB_",
        "colab_type": "code",
        "outputId": "675df989-0b19-41be-f6d3-1dd33a51af94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(trainBBoxImage.shape)\n",
        "print(nonOverlappingIndices.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12795, 50, 50, 1)\n",
            "(14216,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtOVaOHVuRIj",
        "colab_type": "code",
        "outputId": "245bb630-3ec7-4b7b-9554-bd678f6848ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "import keras\n",
        "y_train = keras.utils.to_categorical(trainPred, num_classes=total_classes)\n",
        "y_test = keras.utils.to_categorical(testPred, num_classes=total_classes)\n",
        "\n",
        "print(np.sum(y_train, axis=0))\n",
        "print(total_classes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[5811. 3601. 1592. 1791.]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8kFslEMP3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9PAwvvQMy08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlzLaJzVh_wX",
        "colab_type": "code",
        "outputId": "ba63a804-7006-4fac-d410-8ba4b87ac9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "uniqueCode = \"model_\"\n",
        "for i in range(20):\n",
        "  c = ord('a') + np.random.randint(0, 26, 1)\n",
        "  uniqueCode += chr(c)\n",
        "print(uniqueCode)\n",
        "\n",
        "!mkdir {uniqueCode}\n",
        "\n",
        "print(\"Model Name = \",uniqueCode)\n",
        "\n",
        "inputBBoxImage = Input(shape=(50, 50, 1))\n",
        "inputObjLatentVector = Input(shape=(9216,))\n",
        "inputSubLatentVector = Input(shape=(9216,))\n",
        "inputObjWordVector = Input(shape=(50,))\n",
        "inputSubWordVector = Input(shape=(50,))\n",
        "\n",
        "\n",
        "\n",
        "z1 = Conv2D(32, (11, 11), activation='relu', padding='same')(inputBBoxImage)\n",
        "z2 = Conv2D(32, (11, 11), activation='relu', padding='same')(z1)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z1 = Conv2D(32, (11, 11), activation='relu', padding='same')(z)\n",
        "z2 = Conv2D(32, (11, 11), activation='relu', padding='same')(z1)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z = MaxPooling2D((2, 2))(z)\n",
        "z = Dropout(0.25)(z)\n",
        "\n",
        "z1 = Conv2D(64, (9, 9), activation='relu', padding='same')(z)\n",
        "z2 = Conv2D(64, (9, 9), activation='relu', padding='same')(z1)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z1 = Conv2D(64, (9, 9), activation='relu', padding='same')(z)\n",
        "z2 = Conv2D(64, (9, 9), activation='relu', padding='same')(z1)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z = MaxPooling2D((2, 2))(z)\n",
        "z = Dropout(0.25)(z)\n",
        "\n",
        "z1 = Conv2D(128, (7, 7), activation='relu', padding='same')(z)\n",
        "z2 = Conv2D(128, (7, 7), activation='relu', padding='same')(z1)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z1 = Conv2D(128, (7, 7), activation='relu', padding='same')(z)\n",
        "z2 = Conv2D(128, (7, 7), activation='relu', padding='same')(z2)\n",
        "z = keras.layers.add([z1, z2])\n",
        "z = MaxPooling2D((2, 2))(z)\n",
        "z = Dropout(0.25)(z)\n",
        "\n",
        "z = Flatten()(z)\n",
        "concatenated = keras.layers.concatenate([z, inputObjLatentVector, inputSubLatentVector, inputObjWordVector, inputSubWordVector])\n",
        "concatenated = Dense(1024, activation='relu')(concatenated)\n",
        "concatenated = Dense(128, activation='relu')(concatenated)\n",
        "concatenated = Dropout(0.25)(concatenated)\n",
        "out = Dense(total_classes, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([inputBBoxImage, inputObjLatentVector, inputSubLatentVector, inputObjWordVector, inputSubWordVector], out)\n",
        "\n",
        "learning_rate = 0.00003\n",
        "\n",
        "adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy', precision_m, recall_m, f1_m])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "filepath = \"best_model.h5\"\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "batch_size = 64\n",
        "epochs = 400\n",
        "\n",
        "model.fit([trainBBoxImage, trainObjLatentVector, trainSubLatentVector, trainObjWordVector, trainSubWordVector], [y_train], verbose=1,\n",
        "            epochs=2, batch_size=batch_size, shuffle=True, validation_split=0.1, callbacks=[reduce_lr, model_checkpoint])\n",
        "\n",
        "learning_rate2 = 1.73205e-5\n",
        "adam2 = Adam(lr=learning_rate2, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer=adam2, loss=focal_loss(alpha=1), metrics=['accuracy', precision_m, recall_m, f1_m])\n",
        "model.fit([trainBBoxImage, trainObjLatentVector, trainSubLatentVector, trainObjWordVector, trainSubWordVector], [y_train], verbose=1,\n",
        "            epochs=18, batch_size=batch_size, shuffle=True, validation_split=0.1, callbacks=[reduce_lr, model_checkpoint])\n",
        "\n",
        "learning_rate3 = 7.59835e-6\n",
        "adam3 = Adam(lr=learning_rate3, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer=adam3, loss=focal_loss(alpha=1), metrics=['accuracy', precision_m, recall_m, f1_m])\n",
        "model.fit([trainBBoxImage, trainObjLatentVector, trainSubLatentVector, trainObjWordVector, trainSubWordVector], [y_train], verbose=1,\n",
        "            epochs=epochs-20, batch_size=batch_size, shuffle=True, validation_split=0.1, callbacks=[reduce_lr, model_checkpoint])\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_vvvrpwhxwavgcfeawika\n",
            "Model Name =  model_vvvrpwhxwavgcfeawika\n",
            "Train on 11515 samples, validate on 1280 samples\n",
            "Epoch 1/2\n",
            "11515/11515 [==============================] - 14s 1ms/step - loss: 1.3834 - acc: 0.5153 - precision_m: 0.6130 - recall_m: 0.3337 - f1_m: 0.4271 - val_loss: 0.9603 - val_acc: 0.6125 - val_precision_m: 0.6957 - val_recall_m: 0.4734 - val_f1_m: 0.5627\n",
            "Epoch 2/2\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.8460 - acc: 0.6621 - precision_m: 0.7565 - recall_m: 0.5316 - f1_m: 0.6231 - val_loss: 0.9024 - val_acc: 0.6445 - val_precision_m: 0.7152 - val_recall_m: 0.5508 - val_f1_m: 0.6216\n",
            "Train on 11515 samples, validate on 1280 samples\n",
            "Epoch 1/18\n",
            "11515/11515 [==============================] - 14s 1ms/step - loss: 0.2688 - acc: 0.7720 - precision_m: 0.8852 - recall_m: 0.6066 - f1_m: 0.7185 - val_loss: 0.4606 - val_acc: 0.6492 - val_precision_m: 0.7567 - val_recall_m: 0.4852 - val_f1_m: 0.5894\n",
            "Epoch 2/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.1738 - acc: 0.8565 - precision_m: 0.9295 - recall_m: 0.7134 - f1_m: 0.8062 - val_loss: 0.4573 - val_acc: 0.6516 - val_precision_m: 0.7493 - val_recall_m: 0.5109 - val_f1_m: 0.6066\n",
            "Epoch 3/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.1219 - acc: 0.8967 - precision_m: 0.9508 - recall_m: 0.7928 - f1_m: 0.8639 - val_loss: 0.4629 - val_acc: 0.6711 - val_precision_m: 0.7437 - val_recall_m: 0.5469 - val_f1_m: 0.6292\n",
            "Epoch 4/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0846 - acc: 0.9356 - precision_m: 0.9722 - recall_m: 0.8589 - f1_m: 0.9115 - val_loss: 0.4673 - val_acc: 0.6719 - val_precision_m: 0.7479 - val_recall_m: 0.5531 - val_f1_m: 0.6349\n",
            "Epoch 5/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0611 - acc: 0.9557 - precision_m: 0.9807 - recall_m: 0.9009 - f1_m: 0.9388 - val_loss: 0.4937 - val_acc: 0.6672 - val_precision_m: 0.7262 - val_recall_m: 0.5703 - val_f1_m: 0.6383\n",
            "Epoch 6/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0468 - acc: 0.9682 - precision_m: 0.9838 - recall_m: 0.9297 - f1_m: 0.9558 - val_loss: 0.5062 - val_acc: 0.6711 - val_precision_m: 0.7310 - val_recall_m: 0.5813 - val_f1_m: 0.6471\n",
            "Epoch 7/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0361 - acc: 0.9795 - precision_m: 0.9894 - recall_m: 0.9494 - f1_m: 0.9688 - val_loss: 0.5035 - val_acc: 0.6680 - val_precision_m: 0.7283 - val_recall_m: 0.5891 - val_f1_m: 0.6507\n",
            "Epoch 8/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0283 - acc: 0.9840 - precision_m: 0.9912 - recall_m: 0.9634 - f1_m: 0.9770 - val_loss: 0.5204 - val_acc: 0.6687 - val_precision_m: 0.7097 - val_recall_m: 0.5914 - val_f1_m: 0.6445\n",
            "Epoch 9/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0232 - acc: 0.9862 - precision_m: 0.9914 - recall_m: 0.9716 - f1_m: 0.9813 - val_loss: 0.5261 - val_acc: 0.6703 - val_precision_m: 0.7185 - val_recall_m: 0.5969 - val_f1_m: 0.6514\n",
            "Epoch 10/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0199 - acc: 0.9884 - precision_m: 0.9935 - recall_m: 0.9752 - f1_m: 0.9842 - val_loss: 0.5190 - val_acc: 0.6750 - val_precision_m: 0.7270 - val_recall_m: 0.6016 - val_f1_m: 0.6577\n",
            "Epoch 11/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0174 - acc: 0.9903 - precision_m: 0.9944 - recall_m: 0.9815 - f1_m: 0.9879 - val_loss: 0.5488 - val_acc: 0.6734 - val_precision_m: 0.7119 - val_recall_m: 0.6133 - val_f1_m: 0.6584\n",
            "Epoch 12/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0137 - acc: 0.9920 - precision_m: 0.9950 - recall_m: 0.9850 - f1_m: 0.9899 - val_loss: 0.5531 - val_acc: 0.6711 - val_precision_m: 0.7073 - val_recall_m: 0.6039 - val_f1_m: 0.6513\n",
            "Epoch 13/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0140 - acc: 0.9924 - precision_m: 0.9947 - recall_m: 0.9851 - f1_m: 0.9898 - val_loss: 0.6074 - val_acc: 0.6750 - val_precision_m: 0.7108 - val_recall_m: 0.6219 - val_f1_m: 0.6631\n",
            "Epoch 14/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0115 - acc: 0.9931 - precision_m: 0.9955 - recall_m: 0.9875 - f1_m: 0.9914 - val_loss: 0.5760 - val_acc: 0.6773 - val_precision_m: 0.7163 - val_recall_m: 0.6297 - val_f1_m: 0.6699\n",
            "Epoch 15/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0091 - acc: 0.9955 - precision_m: 0.9971 - recall_m: 0.9911 - f1_m: 0.9941 - val_loss: 0.5759 - val_acc: 0.6734 - val_precision_m: 0.7096 - val_recall_m: 0.6141 - val_f1_m: 0.6580\n",
            "Epoch 16/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0087 - acc: 0.9964 - precision_m: 0.9974 - recall_m: 0.9924 - f1_m: 0.9949 - val_loss: 0.5992 - val_acc: 0.6781 - val_precision_m: 0.7112 - val_recall_m: 0.6344 - val_f1_m: 0.6704\n",
            "Epoch 17/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0080 - acc: 0.9958 - precision_m: 0.9978 - recall_m: 0.9925 - f1_m: 0.9951 - val_loss: 0.5821 - val_acc: 0.6844 - val_precision_m: 0.7224 - val_recall_m: 0.6289 - val_f1_m: 0.6721\n",
            "Epoch 18/18\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0064 - acc: 0.9968 - precision_m: 0.9982 - recall_m: 0.9945 - f1_m: 0.9963 - val_loss: 0.6350 - val_acc: 0.6773 - val_precision_m: 0.7018 - val_recall_m: 0.6312 - val_f1_m: 0.6644\n",
            "Train on 11515 samples, validate on 1280 samples\n",
            "Epoch 1/380\n",
            "11515/11515 [==============================] - 14s 1ms/step - loss: 0.0057 - acc: 0.9977 - precision_m: 0.9985 - recall_m: 0.9947 - f1_m: 0.9966 - val_loss: 0.6484 - val_acc: 0.6773 - val_precision_m: 0.7004 - val_recall_m: 0.6312 - val_f1_m: 0.6638\n",
            "Epoch 2/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0049 - acc: 0.9979 - precision_m: 0.9983 - recall_m: 0.9960 - f1_m: 0.9972 - val_loss: 0.6568 - val_acc: 0.6781 - val_precision_m: 0.7054 - val_recall_m: 0.6375 - val_f1_m: 0.6694\n",
            "Epoch 3/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0037 - acc: 0.9987 - precision_m: 0.9990 - recall_m: 0.9978 - f1_m: 0.9984 - val_loss: 0.6634 - val_acc: 0.6719 - val_precision_m: 0.7032 - val_recall_m: 0.6391 - val_f1_m: 0.6694\n",
            "Epoch 4/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0048 - acc: 0.9977 - precision_m: 0.9982 - recall_m: 0.9961 - f1_m: 0.9971 - val_loss: 0.6233 - val_acc: 0.6836 - val_precision_m: 0.7082 - val_recall_m: 0.6367 - val_f1_m: 0.6702\n",
            "Epoch 5/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0038 - acc: 0.9983 - precision_m: 0.9986 - recall_m: 0.9977 - f1_m: 0.9982 - val_loss: 0.6888 - val_acc: 0.6687 - val_precision_m: 0.6907 - val_recall_m: 0.6375 - val_f1_m: 0.6629\n",
            "Epoch 6/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0040 - acc: 0.9983 - precision_m: 0.9986 - recall_m: 0.9967 - f1_m: 0.9976 - val_loss: 0.6747 - val_acc: 0.6672 - val_precision_m: 0.6955 - val_recall_m: 0.6414 - val_f1_m: 0.6672\n",
            "Epoch 7/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0029 - acc: 0.9989 - precision_m: 0.9990 - recall_m: 0.9980 - f1_m: 0.9985 - val_loss: 0.6620 - val_acc: 0.6820 - val_precision_m: 0.7083 - val_recall_m: 0.6430 - val_f1_m: 0.6738\n",
            "Epoch 8/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0032 - acc: 0.9989 - precision_m: 0.9990 - recall_m: 0.9980 - f1_m: 0.9985 - val_loss: 0.6816 - val_acc: 0.6875 - val_precision_m: 0.7152 - val_recall_m: 0.6508 - val_f1_m: 0.6812\n",
            "Epoch 9/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0031 - acc: 0.9985 - precision_m: 0.9987 - recall_m: 0.9982 - f1_m: 0.9984 - val_loss: 0.6531 - val_acc: 0.6781 - val_precision_m: 0.7076 - val_recall_m: 0.6438 - val_f1_m: 0.6739\n",
            "Epoch 10/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0030 - acc: 0.9983 - precision_m: 0.9988 - recall_m: 0.9977 - f1_m: 0.9982 - val_loss: 0.6885 - val_acc: 0.6883 - val_precision_m: 0.7104 - val_recall_m: 0.6516 - val_f1_m: 0.6794\n",
            "Epoch 11/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0025 - acc: 0.9987 - precision_m: 0.9989 - recall_m: 0.9977 - f1_m: 0.9983 - val_loss: 0.6990 - val_acc: 0.6836 - val_precision_m: 0.7105 - val_recall_m: 0.6555 - val_f1_m: 0.6817\n",
            "Epoch 12/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0025 - acc: 0.9986 - precision_m: 0.9986 - recall_m: 0.9982 - f1_m: 0.9984 - val_loss: 0.6493 - val_acc: 0.6813 - val_precision_m: 0.7141 - val_recall_m: 0.6469 - val_f1_m: 0.6786\n",
            "Epoch 13/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0024 - acc: 0.9990 - precision_m: 0.9993 - recall_m: 0.9983 - f1_m: 0.9988 - val_loss: 0.6919 - val_acc: 0.6828 - val_precision_m: 0.7082 - val_recall_m: 0.6531 - val_f1_m: 0.6793\n",
            "Epoch 14/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0025 - acc: 0.9990 - precision_m: 0.9992 - recall_m: 0.9986 - f1_m: 0.9989 - val_loss: 0.7158 - val_acc: 0.6844 - val_precision_m: 0.7081 - val_recall_m: 0.6570 - val_f1_m: 0.6813\n",
            "Epoch 15/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0024 - acc: 0.9990 - precision_m: 0.9990 - recall_m: 0.9983 - f1_m: 0.9987 - val_loss: 0.7316 - val_acc: 0.6758 - val_precision_m: 0.7015 - val_recall_m: 0.6570 - val_f1_m: 0.6784\n",
            "Epoch 16/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9999 - recall_m: 0.9990 - f1_m: 0.9995 - val_loss: 0.7069 - val_acc: 0.6844 - val_precision_m: 0.7057 - val_recall_m: 0.6461 - val_f1_m: 0.6743\n",
            "Epoch 17/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0021 - acc: 0.9991 - precision_m: 0.9992 - recall_m: 0.9988 - f1_m: 0.9990 - val_loss: 0.7641 - val_acc: 0.6781 - val_precision_m: 0.6964 - val_recall_m: 0.6500 - val_f1_m: 0.6722\n",
            "Epoch 18/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0016 - acc: 0.9989 - precision_m: 0.9991 - recall_m: 0.9988 - f1_m: 0.9990 - val_loss: 0.7077 - val_acc: 0.6930 - val_precision_m: 0.7131 - val_recall_m: 0.6570 - val_f1_m: 0.6836\n",
            "Epoch 19/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0020 - acc: 0.9991 - precision_m: 0.9992 - recall_m: 0.9987 - f1_m: 0.9990 - val_loss: 0.7616 - val_acc: 0.6820 - val_precision_m: 0.6973 - val_recall_m: 0.6547 - val_f1_m: 0.6752\n",
            "Epoch 20/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0014 - acc: 0.9993 - precision_m: 0.9994 - recall_m: 0.9991 - f1_m: 0.9993 - val_loss: 0.7521 - val_acc: 0.6742 - val_precision_m: 0.7041 - val_recall_m: 0.6531 - val_f1_m: 0.6774\n",
            "Epoch 21/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0021 - acc: 0.9991 - precision_m: 0.9991 - recall_m: 0.9989 - f1_m: 0.9990 - val_loss: 0.7668 - val_acc: 0.6789 - val_precision_m: 0.6992 - val_recall_m: 0.6523 - val_f1_m: 0.6747\n",
            "Epoch 22/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0015 - acc: 0.9991 - precision_m: 0.9991 - recall_m: 0.9990 - f1_m: 0.9991 - val_loss: 0.7425 - val_acc: 0.6805 - val_precision_m: 0.6988 - val_recall_m: 0.6516 - val_f1_m: 0.6742\n",
            "Epoch 23/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0025 - acc: 0.9988 - precision_m: 0.9989 - recall_m: 0.9984 - f1_m: 0.9987 - val_loss: 0.7516 - val_acc: 0.6828 - val_precision_m: 0.7080 - val_recall_m: 0.6570 - val_f1_m: 0.6813\n",
            "Epoch 24/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0018 - acc: 0.9990 - precision_m: 0.9992 - recall_m: 0.9987 - f1_m: 0.9990 - val_loss: 0.7997 - val_acc: 0.6727 - val_precision_m: 0.6951 - val_recall_m: 0.6508 - val_f1_m: 0.6720\n",
            "Epoch 25/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0014 - acc: 0.9993 - precision_m: 0.9993 - recall_m: 0.9991 - f1_m: 0.9992 - val_loss: 0.7463 - val_acc: 0.6914 - val_precision_m: 0.7128 - val_recall_m: 0.6641 - val_f1_m: 0.6874\n",
            "Epoch 26/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0013 - acc: 0.9993 - precision_m: 0.9994 - recall_m: 0.9992 - f1_m: 0.9993 - val_loss: 0.7127 - val_acc: 0.6836 - val_precision_m: 0.7120 - val_recall_m: 0.6539 - val_f1_m: 0.6815\n",
            "Epoch 27/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0014 - acc: 0.9990 - precision_m: 0.9991 - recall_m: 0.9990 - f1_m: 0.9990 - val_loss: 0.7191 - val_acc: 0.6859 - val_precision_m: 0.7136 - val_recall_m: 0.6594 - val_f1_m: 0.6853\n",
            "Epoch 28/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0019 - acc: 0.9990 - precision_m: 0.9992 - recall_m: 0.9987 - f1_m: 0.9990 - val_loss: 0.7236 - val_acc: 0.6844 - val_precision_m: 0.7051 - val_recall_m: 0.6531 - val_f1_m: 0.6779\n",
            "Epoch 29/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0015 - acc: 0.9994 - precision_m: 0.9994 - recall_m: 0.9991 - f1_m: 0.9993 - val_loss: 0.7462 - val_acc: 0.6844 - val_precision_m: 0.7039 - val_recall_m: 0.6594 - val_f1_m: 0.6807\n",
            "Epoch 30/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0013 - acc: 0.9994 - precision_m: 0.9994 - recall_m: 0.9994 - f1_m: 0.9994 - val_loss: 0.7300 - val_acc: 0.6836 - val_precision_m: 0.7071 - val_recall_m: 0.6562 - val_f1_m: 0.6806\n",
            "Epoch 31/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0010 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7448 - val_acc: 0.6867 - val_precision_m: 0.7087 - val_recall_m: 0.6625 - val_f1_m: 0.6846\n",
            "Epoch 32/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0010 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7533 - val_acc: 0.6852 - val_precision_m: 0.7088 - val_recall_m: 0.6617 - val_f1_m: 0.6843\n",
            "Epoch 33/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 7.3432e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7480 - val_acc: 0.6875 - val_precision_m: 0.7125 - val_recall_m: 0.6617 - val_f1_m: 0.6860\n",
            "Epoch 34/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 0.0012 - acc: 0.9993 - precision_m: 0.9993 - recall_m: 0.9992 - f1_m: 0.9993 - val_loss: 0.7590 - val_acc: 0.6891 - val_precision_m: 0.7089 - val_recall_m: 0.6617 - val_f1_m: 0.6843\n",
            "Epoch 35/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 7.0151e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7578 - val_acc: 0.6953 - val_precision_m: 0.7101 - val_recall_m: 0.6641 - val_f1_m: 0.6861\n",
            "Epoch 36/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.1507e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7609 - val_acc: 0.6937 - val_precision_m: 0.7133 - val_recall_m: 0.6672 - val_f1_m: 0.6893\n",
            "Epoch 37/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 7.6233e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9994 - f1_m: 0.9995 - val_loss: 0.7524 - val_acc: 0.6945 - val_precision_m: 0.7195 - val_recall_m: 0.6664 - val_f1_m: 0.6918\n",
            "Epoch 38/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.5669e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9993 - f1_m: 0.9994 - val_loss: 0.7646 - val_acc: 0.6953 - val_precision_m: 0.7117 - val_recall_m: 0.6664 - val_f1_m: 0.6882\n",
            "Epoch 39/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 7.3422e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7597 - val_acc: 0.6945 - val_precision_m: 0.7101 - val_recall_m: 0.6609 - val_f1_m: 0.6844\n",
            "Epoch 40/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.7716e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7631 - val_acc: 0.6969 - val_precision_m: 0.7110 - val_recall_m: 0.6648 - val_f1_m: 0.6870\n",
            "Epoch 41/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 7.4944e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7715 - val_acc: 0.6953 - val_precision_m: 0.7113 - val_recall_m: 0.6680 - val_f1_m: 0.6888\n",
            "Epoch 42/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.2393e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7660 - val_acc: 0.6930 - val_precision_m: 0.7080 - val_recall_m: 0.6625 - val_f1_m: 0.6844\n",
            "Epoch 43/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.9102e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9995 - f1_m: 0.9996 - val_loss: 0.7752 - val_acc: 0.6969 - val_precision_m: 0.7108 - val_recall_m: 0.6664 - val_f1_m: 0.6878\n",
            "Epoch 44/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.2428e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7874 - val_acc: 0.6969 - val_precision_m: 0.7099 - val_recall_m: 0.6672 - val_f1_m: 0.6877\n",
            "Epoch 45/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.8848e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7717 - val_acc: 0.6953 - val_precision_m: 0.7101 - val_recall_m: 0.6680 - val_f1_m: 0.6882\n",
            "Epoch 46/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.5898e-04 - acc: 1.0000 - precision_m: 1.0000 - recall_m: 0.9999 - f1_m: 1.0000 - val_loss: 0.7919 - val_acc: 0.6961 - val_precision_m: 0.7081 - val_recall_m: 0.6711 - val_f1_m: 0.6890\n",
            "Epoch 47/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.2530e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7739 - val_acc: 0.6953 - val_precision_m: 0.7069 - val_recall_m: 0.6672 - val_f1_m: 0.6863\n",
            "Epoch 48/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.4364e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9994 - f1_m: 0.9995 - val_loss: 0.7809 - val_acc: 0.6945 - val_precision_m: 0.7106 - val_recall_m: 0.6656 - val_f1_m: 0.6872\n",
            "Epoch 49/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.1238e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7735 - val_acc: 0.6977 - val_precision_m: 0.7113 - val_recall_m: 0.6664 - val_f1_m: 0.6879\n",
            "Epoch 50/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.4039e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7803 - val_acc: 0.6922 - val_precision_m: 0.7089 - val_recall_m: 0.6664 - val_f1_m: 0.6868\n",
            "Epoch 51/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.4919e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7850 - val_acc: 0.6945 - val_precision_m: 0.7069 - val_recall_m: 0.6656 - val_f1_m: 0.6855\n",
            "Epoch 52/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.3595e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7803 - val_acc: 0.6922 - val_precision_m: 0.7084 - val_recall_m: 0.6664 - val_f1_m: 0.6867\n",
            "Epoch 53/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.1957e-04 - acc: 1.0000 - precision_m: 1.0000 - recall_m: 0.9998 - f1_m: 0.9999 - val_loss: 0.7887 - val_acc: 0.6953 - val_precision_m: 0.7099 - val_recall_m: 0.6687 - val_f1_m: 0.6885\n",
            "Epoch 54/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.9972e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - f1_m: 0.9998 - val_loss: 0.7911 - val_acc: 0.6945 - val_precision_m: 0.7089 - val_recall_m: 0.6711 - val_f1_m: 0.6894\n",
            "Epoch 55/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6041e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - f1_m: 0.9998 - val_loss: 0.7935 - val_acc: 0.6945 - val_precision_m: 0.7103 - val_recall_m: 0.6703 - val_f1_m: 0.6896\n",
            "Epoch 56/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6219e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7928 - val_acc: 0.6930 - val_precision_m: 0.7098 - val_recall_m: 0.6687 - val_f1_m: 0.6885\n",
            "Epoch 57/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.0566e-04 - acc: 0.9997 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7918 - val_acc: 0.6953 - val_precision_m: 0.7110 - val_recall_m: 0.6703 - val_f1_m: 0.6899\n",
            "Epoch 58/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.5881e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7909 - val_acc: 0.6930 - val_precision_m: 0.7058 - val_recall_m: 0.6672 - val_f1_m: 0.6858\n",
            "Epoch 59/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.1155e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9994 - f1_m: 0.9994 - val_loss: 0.7816 - val_acc: 0.6945 - val_precision_m: 0.7081 - val_recall_m: 0.6711 - val_f1_m: 0.6890\n",
            "Epoch 60/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.0826e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - f1_m: 0.9998 - val_loss: 0.7838 - val_acc: 0.6945 - val_precision_m: 0.7082 - val_recall_m: 0.6711 - val_f1_m: 0.6890\n",
            "Epoch 61/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.9707e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7862 - val_acc: 0.6937 - val_precision_m: 0.7078 - val_recall_m: 0.6719 - val_f1_m: 0.6892\n",
            "Epoch 62/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.1513e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7852 - val_acc: 0.6937 - val_precision_m: 0.7075 - val_recall_m: 0.6711 - val_f1_m: 0.6887\n",
            "Epoch 63/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 6.5322e-04 - acc: 0.9993 - precision_m: 0.9993 - recall_m: 0.9991 - f1_m: 0.9992 - val_loss: 0.7858 - val_acc: 0.6945 - val_precision_m: 0.7084 - val_recall_m: 0.6734 - val_f1_m: 0.6904\n",
            "Epoch 64/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.3764e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7880 - val_acc: 0.6930 - val_precision_m: 0.7086 - val_recall_m: 0.6719 - val_f1_m: 0.6896\n",
            "Epoch 65/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6298e-04 - acc: 0.9997 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7888 - val_acc: 0.6930 - val_precision_m: 0.7096 - val_recall_m: 0.6719 - val_f1_m: 0.6901\n",
            "Epoch 66/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.4100e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7869 - val_acc: 0.6945 - val_precision_m: 0.7079 - val_recall_m: 0.6703 - val_f1_m: 0.6884\n",
            "Epoch 67/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.9410e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7881 - val_acc: 0.6945 - val_precision_m: 0.7079 - val_recall_m: 0.6719 - val_f1_m: 0.6893\n",
            "Epoch 68/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.7554e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7871 - val_acc: 0.6945 - val_precision_m: 0.7072 - val_recall_m: 0.6719 - val_f1_m: 0.6890\n",
            "Epoch 69/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.3082e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7857 - val_acc: 0.6961 - val_precision_m: 0.7080 - val_recall_m: 0.6703 - val_f1_m: 0.6885\n",
            "Epoch 70/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.4737e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9994 - f1_m: 0.9995 - val_loss: 0.7857 - val_acc: 0.6961 - val_precision_m: 0.7078 - val_recall_m: 0.6719 - val_f1_m: 0.6892\n",
            "Epoch 71/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.3080e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7859 - val_acc: 0.6961 - val_precision_m: 0.7078 - val_recall_m: 0.6719 - val_f1_m: 0.6892\n",
            "Epoch 72/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.7806e-04 - acc: 0.9997 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7861 - val_acc: 0.6961 - val_precision_m: 0.7078 - val_recall_m: 0.6719 - val_f1_m: 0.6892\n",
            "Epoch 73/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.2143e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9994 - f1_m: 0.9995 - val_loss: 0.7859 - val_acc: 0.6961 - val_precision_m: 0.7078 - val_recall_m: 0.6719 - val_f1_m: 0.6892\n",
            "Epoch 74/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.0565e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7863 - val_acc: 0.6969 - val_precision_m: 0.7081 - val_recall_m: 0.6727 - val_f1_m: 0.6898\n",
            "Epoch 75/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.1425e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7081 - val_recall_m: 0.6727 - val_f1_m: 0.6898\n",
            "Epoch 76/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.7028e-04 - acc: 0.9997 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7864 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 77/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 3.8796e-04 - acc: 0.9999 - precision_m: 0.9999 - recall_m: 0.9998 - f1_m: 0.9999 - val_loss: 0.7864 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 78/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.4234e-04 - acc: 0.9999 - precision_m: 0.9999 - recall_m: 0.9999 - f1_m: 0.9999 - val_loss: 0.7865 - val_acc: 0.6969 - val_precision_m: 0.7086 - val_recall_m: 0.6727 - val_f1_m: 0.6901\n",
            "Epoch 79/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.1118e-04 - acc: 0.9995 - precision_m: 0.9995 - recall_m: 0.9994 - f1_m: 0.9994 - val_loss: 0.7865 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 80/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.9924e-04 - acc: 0.9994 - precision_m: 0.9996 - recall_m: 0.9993 - f1_m: 0.9994 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 81/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.1129e-04 - acc: 0.9999 - precision_m: 0.9999 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 82/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.0613e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 83/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 3.8848e-04 - acc: 0.9998 - precision_m: 0.9999 - recall_m: 0.9998 - f1_m: 0.9999 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 84/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6707e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 85/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.0646e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 86/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.0454e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 87/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.8346e-04 - acc: 0.9994 - precision_m: 0.9996 - recall_m: 0.9992 - f1_m: 0.9994 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 88/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.3412e-04 - acc: 0.9996 - precision_m: 0.9997 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 89/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.8890e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 90/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.3483e-04 - acc: 0.9999 - precision_m: 0.9999 - recall_m: 0.9999 - f1_m: 0.9999 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 91/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.1847e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 92/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.0933e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 93/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.7411e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9996 - f1_m: 0.9996 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 94/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 3.9603e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 95/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.9054e-04 - acc: 0.9996 - precision_m: 0.9996 - recall_m: 0.9995 - f1_m: 0.9995 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 96/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.4242e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 97/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.0473e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 98/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.1258e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 99/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.7737e-04 - acc: 0.9994 - precision_m: 0.9995 - recall_m: 0.9993 - f1_m: 0.9994 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 100/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.3315e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 101/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 3.8735e-04 - acc: 0.9998 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 102/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6334e-04 - acc: 0.9999 - precision_m: 0.9999 - recall_m: 0.9997 - f1_m: 0.9998 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 103/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 5.0072e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 104/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.1486e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 105/380\n",
            "11515/11515 [==============================] - 12s 1ms/step - loss: 4.6901e-04 - acc: 0.9997 - precision_m: 0.9997 - recall_m: 0.9997 - f1_m: 0.9997 - val_loss: 0.7866 - val_acc: 0.6969 - val_precision_m: 0.7089 - val_recall_m: 0.6734 - val_f1_m: 0.6906\n",
            "Epoch 106/380\n",
            "10112/11515 [=========================>....] - ETA: 1s - loss: 4.2135e-04 - acc: 0.9997 - precision_m: 0.9998 - recall_m: 0.9997 - f1_m: 0.9998"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9b714fa72418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfocal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m model.fit([trainBBoxImage, trainObjLatentVector, trainSubLatentVector, trainObjWordVector, trainSubWordVector], [y_train], verbose=1,\n\u001b[0;32m--> 240\u001b[0;31m             epochs=epochs-20, batch_size=batch_size, shuffle=True, validation_split=0.1, callbacks=[reduce_lr, model_checkpoint])\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;31m# for i in range(20, epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m#   pre = datetime.now()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5APhqxPRRjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49fc3444-dc18-4df3-9f8a-fa3d6811f9a4"
      },
      "source": [
        "performance = model.evaluate(x=[testBBoxImage, testObjLatentVector, testSubLatentVector, testObjWordVector, testSubWordVector], y=[y_test], batch_size=batch_size, verbose=0)\n",
        "print(performance)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7360104539711487, 0.6903589024332356, 0.7070171431199839, 0.6586910628836227, 0.6817479650794747]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FptPzT2QUxnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}